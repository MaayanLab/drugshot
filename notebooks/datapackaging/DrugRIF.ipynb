{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch all unique small molecules from Drugmonizome by InChI Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_entities = requests.get(\"https://maayanlab.cloud/drugmonizome/metadata-api/entities\").json()\n",
    "len(uploaded_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_dict = {}\n",
    "for entity in uploaded_entities:\n",
    "    name = entity['meta']['Name']\n",
    "    inchikey = entity['meta']['InChI_key']\n",
    "    synonym_dict[inchikey] = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch all unique small molecules from SEP-L1000 by InChI Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1000 drugs with expression signatures\n",
    "L1000_DATA = 'https://appyters.maayanlab.cloud/storage/Drugmonizome_ML/SEP-L1000/LINCS_Gene_Experssion_signatures_CD.csv.gz'\n",
    "l1000data_df = pd.read_csv(L1000_DATA).set_index('InChI Key')\n",
    "\n",
    "# L1000 drug metadata\n",
    "L1000_METADATA = 'https://maayanlab.cloud/L1000FWD/download/Drugs_metadata.csv'\n",
    "l1000meta_df = pd.read_csv(L1000_METADATA, index_col=5)\n",
    "l1000meta_df.index = l1000meta_df.index.map(lambda s: s.replace('InChIKey=', '') if isinstance(s, str) else s)\n",
    "l1000meta_df = l1000meta_df.iloc[np.logical_not(l1000meta_df.index.duplicated())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1000_dict = dict(zip(l1000data_df.index, l1000meta_df['pert_iname'].reindex(l1000data_df.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_dict.update(l1000_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(synonym_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import list of compounds to filter out... these are not considered small molecules\n",
    "with open('compounds-to-filter.txt', 'r') as f:\n",
    "    filter_list = [x.strip().lower() for x in f.read().strip().split('\\n')]\n",
    "    \n",
    "# Filter unwanted compounds from synonym_dict\n",
    "synonym_dict = {k:v for k,v in synonym_dict.items() if v not in filter_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PubChem Search for PubMed IDs associated with each InChI Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xref_url = 'https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/inchikey/%s/xrefs/PubMedID/JSON'\n",
    "\n",
    "pmid_dict = {}\n",
    "output = []\n",
    "\n",
    "failed = []\n",
    "\n",
    "for inchikey,name in tqdm(synonym_dict.items()):\n",
    "    response = requests.get(xref_url%inchikey)\n",
    "    try:\n",
    "        response.json()\n",
    "    except ValueError:\n",
    "        continue\n",
    "    pmids = []\n",
    "    if 'InformationList' in response.json().keys():\n",
    "        for entry in response.json()['InformationList']['Information']:\n",
    "            if 'PubMedID' in entry:\n",
    "                pmids.extend(entry['PubMedID'])\n",
    "                \n",
    "    else:\n",
    "        failed.append(inchikey)\n",
    "    \n",
    "    if len(set(pmids)) >= 2:\n",
    "        for i in pmids:\n",
    "            output.append((inchikey, name, i))\n",
    "    \n",
    "    time.sleep(0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} / {} records could not be retrieved ({} percent)\".format(len(failed),len(synonym_dict), len(failed)/len(synonym_dict)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tsv file of all chemical-PMID associations\n",
    "DrugRIF = pd.DataFrame(data = output, columns = ['inchikey','name','PMID']).set_index('name')\n",
    "DrugRIF = DrugRIF.reset_index().dropna().set_index('name')\n",
    "DrugRIF.drop_duplicates(inplace = True)\n",
    "DrugRIF.to_csv('DrugRIF.tsv.gz', sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DrugShot",
   "language": "python",
   "name": "drugshot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
